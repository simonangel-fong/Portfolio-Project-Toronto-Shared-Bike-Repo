pipeline {
  agent any

  options {
    disableConcurrentBuilds()   // only one instance
    timestamps()    // show timestamp
    timeout(time: 30, unit: 'MINUTES')    // timeout for pipeline run
    skipDefaultCheckout(true)   // Prevents auto SCM checkout

    // discard old builds
    buildDiscarder(
      logRotator(
        // maximum number of the last build logs
        numToKeepStr: '10',   
        // maximum number of the last sets of build artifacts
        artifactNumToKeepStr: '5'   
      )
    )
  }

  environment {
    GITHUB_URL = "https://github.com/simonangel-fong/Portfolio-Project-Toronto-Shared-Bike-Repo.git"
    GITHUB_BRANCH = "feature-dw-dev"
    POSTGRES_DB = "toronto_shared_bike"
  }

  stages {

    // stage('Clone GitHub Repository') {
    //   steps {
    //     cleanWs()
    //     checkout scmGit(
    //       userRemoteConfigs: [[url: "${env.GITHUB_URL}"]],
    //       branches: [[name: "${env.GITHUB_BRANCH}"]]
    //     )
    //   }
    // }

    stage('Start PostgreSQL Database') {
      steps {
        script{
          withCredentials([
            string(credentialsId: 'postgres_user', variable: 'POSTGRES_USER'),
            string(credentialsId: 'postgres_password', variable: 'POSTGRES_PASSWORD'),
            ]) {
              dir("data-warehouse/postgresql"){
                echo "#################### Spin up PGDB ####################"
                sh '''
                  set -Eeu pipefail

                  pwd
                  ls -l
                  docker compose down -v
                  docker compose up -d --build

                  # Wait until Postgres is ready
                  until docker exec -t postgresql bash -lc 'pg_isready -U "$POSTGRES_USER" -d "$POSTGRES_DB"'; do
                    echo "Waiting for PostgreSQL to become ready..."
                    sleep 5
                  done
                '''

                echo "#################### Confirm PGDB ####################"
                sh '''
                  docker ps --format "table {{.Names}}\t{{.Image}}\t{{.Status}}"
                  docker logs --tail=100 postgresql || true
                '''
              }
          }
        }
      }
    }

    stage('Check PostgreSQL Database Objects') {
      steps {
        echo "#################### Check PostgreSQL Database ####################"
        sh 'docker exec postgresql bash /scripts/testing/object_check.sh'
      }
    }
  }

  post {
    always {
      echo "#################### Cleanup PGDB ####################"
      dir("data-warehouse/postgresql"){
        sh 'docker compose down -v || true'
      }

      echo "#################### Cleanup Workspace ####################"
      cleanWs()
    }
    
    failure {
      emailext (
        to: "tech.arguswatcher@gmail.com",
        subject: "FAILURE - ${env.JOB_NAME} (#${env.BUILD_NUMBER})",
        body: "Jenkins pipeline: '${env.JOB_NAME}'\n" +
          "Status: FAILURE \n" +
          "Build URL: ${env.BUILD_URL}"
      )
    }

    success {
      emailext (
        to: "tech@arguswatcher.net",
        subject: "SUCCESS - ${env.JOB_NAME} (#${env.BUILD_NUMBER})",
        body: "Jenkins pipeline: '${env.JOB_NAME}'\n" +
          "Status: SUCCESS \n" +
          "Build URL: ${env.BUILD_URL}"
      )
    }
  }
}