pipeline {
  agent any
  stages
  {
    stage('Copy Raw Data') {
      steps {
        sh '''
        cp -rv /data data-warehouse/postgresql/data
        ls data-warehouse/postgresql/data
        '''
      }
    }
    stage('Start PostgreSQL') {
        environment {
          POSTGRES_USER = 'postgres'
          POSTGRES_PASSWORD = 'SecurePassword123'
          POSTGRES_DB = 'toronto_shared_bike'
          PGDATA = '/var/lib/postgresql/data/pgdata'
        }
      steps {
        sh '''
        docker --version
        docker compose -f data-warehouse/postgresql/docker-compose.yaml down -v
        docker compose -f data-warehouse/postgresql/docker-compose.yaml up -d --build
        '''
      }
    }

    stage('Extract Data') {
      steps {
        sh '''
        docker exec -t postgresql ls /scripts/etl/extract.sh
        '''
      }
    }
    // stage('Transform Data') {
    //   steps {
    //     sh '''
    //     echo Transform
    //     '''
    //   }
    // }
    // stage('Load Data') {
    //   steps {
    //     sh 'echo Load'
    //   }
    // }
    // stage('Refresh MV') {
    //   steps {
    //     sh 'echo Refresh'
    //   }
    // }
    // stage('Export Data') {
    //   steps {
    //     sh 'echo Export'
    //   }
    // }
    // stage('Upload Data') {
    //   steps {
    //     sh 'echo Upload'
    //   }
    // }
    stage('Stop PostgreSQL') {
      steps {
        sh 'docker compose -f data-warehouse/postgresql/docker-compose.yaml down'
      }
    }
  }

  // post {
    // always {
    //   echo 'This will always execute, regardless of success or failure.'
    //   deleteDir() // Clean up workspace
    // }
    // success {
    //   echo 'Pipeline succeeded! Sending success notification.'
    //     // mail to: 'devs@example.com', subject: 'Pipeline Success'
    //     }
    // failure {
    //   echo 'Pipeline failed! Sending failure notification.'
    //     // mail to: 'devs@example.com', subject: 'Pipeline Failure'
    // }
  // }
}
