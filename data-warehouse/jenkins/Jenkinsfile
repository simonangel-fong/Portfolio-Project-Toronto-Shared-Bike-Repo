pipeline {
  agent any

  environment {
    POSTGRES_USER = 'postgres'
    POSTGRES_PASSWORD = 'SecurePassword123'
    POSTGRES_DB = 'toronto_shared_bike'
    PGDATA = '/var/lib/postgresql/data/pgdata'
  }

  stages
  {
    stage('Copy Raw Data') {
      steps {
        sh '''
        cp -rv /data data-warehouse/postgresql/data
        ls data-warehouse/postgresql/data
        '''
      }
    }
    stage('Start PostgreSQL') {
      steps {
        sh '''
        docker --version
        docker compose -f data-warehouse/postgresql/docker-compose.yaml down -v
        docker compose -f data-warehouse/postgresql/docker-compose.yaml up -d --build
        '''
      }
    }

    stage('Extract Data') {
      steps {
        sh '''
        docker exec -t postgresql ls /scripts/etl/extract.sh
        '''
      }
    }
    // stage('Transform Data') {
    //   steps {
    //     sh '''
    //     echo Transform
    //     '''
    //   }
    // }
    // stage('Load Data') {
    //   steps {
    //     sh 'echo Load'
    //   }
    // }
    // stage('Refresh MV') {
    //   steps {
    //     sh 'echo Refresh'
    //   }
    // }
    // stage('Export Data') {
    //   steps {
    //     sh 'echo Export'
    //   }
    // }
    // stage('Upload Data') {
    //   steps {
    //     sh 'echo Upload'
    //   }
    // }
    stage('Stop PostgreSQL') {
      steps {
        sh 'docker compose -f data-warehouse/postgresql/docker-compose.yaml down'
      }
    }
  }

  post {
    always {
      sh '''
      docker --version
      docker compose -f data-warehouse/postgresql/docker-compose.yaml down -v
      '''
    }
    success {
      echo 'Pipeline succeeded! Sending success notification.'
    // mail to: 'devs@example.com', subject: 'Pipeline Success'
    }
    failure {
      echo 'Pipeline failed! Sending failure notification.'
    // mail to: 'devs@example.com', subject: 'Pipeline Failure'
    }
  }
}
