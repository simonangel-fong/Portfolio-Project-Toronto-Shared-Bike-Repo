pipeline {
  agent any

  environment {
    POSTGRES_USER = 'postgres'
    POSTGRES_PASSWORD = 'SecurePassword123'
    POSTGRES_DB = 'toronto_shared_bike'
    PGDATA = '/var/lib/postgresql/data/pgdata'
    S3_PROFILE = 'toronto_shared_bike'
    S3_BUCKET  = 'toronto-shared-bike-data-warehouse-data-bucket'
    RAW_URL = 'https://toronto-shared-bike-data-warehouse-data-bucket.s3.ca-central-1.amazonaws.com/raw/data.zip'
    S3_PREFIX  = "mv" 
    EXPORT_DIR = '/export'
  }

  stages {
    // stage('Start PostgreSQL') {
    //   steps {
    //     sh '''
    //     docker compose -f data-warehouse/postgresql/docker-compose.yaml down -v
    //     docker compose -f data-warehouse/postgresql/docker-compose.yaml up -d --build
    //     sleep 30
    //     docker logs postgresql
    //     '''
    //   }
    // }

    // stage('Extract Data') {
    //   steps {
    //     sh '''
    //     docker exec -t postgresql bash /scripts/etl/extract.sh
    //     '''
    //   }
    // }
    // stage('Transform Data') {
    //   steps {
    //     sh '''
    //     docker exec -t postgresql bash /scripts/etl/transform.sh
    //     '''
    //   }
    // }
    // stage('Load Data') {
    //   steps {
    //     sh '''
    //     docker exec -t postgresql bash /scripts/etl/load.sh
    //     '''
    //   }
    // }
    // stage('Refresh MV') {
    //   steps {
    //     sh '''
    //     docker exec -t postgresql bash /scripts/mv/mv_refresh.sh
    //     '''
    //   }
    // }
    // stage('Export Data') {
    //   steps {
    //     sh '''
    //     docker exec -t postgresql bash /scripts/export/export.sh
    //     '''
    //   }
    // }
    stage('Upload to S3') {
      steps {
        script{
          withAWS(credentials: 'toronto_shared_bike', region: 'ca-central-1') {
            // sh '''
            // aws s3 cp /export s3://toronto-shared-bike-data-warehouse-data-bucket/test/ --recursive
            // '''
            s3Upload(
              bucket:"toronto-shared-bike-data-warehouse-data-bucket", 
              path:'test', 
              workingDir:'/export',
              includePathPattern:'**/*.csv',
            )
          }
        }
      }
    }
  }

  post {
    always {
      sh '''
      docker compose -f data-warehouse/postgresql/docker-compose.yaml down -v
      '''
    }
    success {
      echo 'Pipeline succeeded! Sending success notification.'
    // mail to: 'devs@example.com', subject: 'Pipeline Success'
    }
    failure {
      echo 'Pipeline failed! Sending failure notification.'
    // mail to: 'devs@example.com', subject: 'Pipeline Failure'
    }
  }
}
