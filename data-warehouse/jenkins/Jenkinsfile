pipeline {
  agent any
  triggers {
    cron 'H H/4 * * *'
  }
  environment {
    POSTGRES_USER = 'postgres'
    POSTGRES_PASSWORD = 'SecurePassword123'
    POSTGRES_DB = 'toronto_shared_bike'
    PGDATA = '/var/lib/postgresql/data/pgdata'
    POSTGRES_DIR = 'data-warehouse/postgresql'
    S3_PROFILE = 'toronto_shared_bike'
    S3_BUCKET  = 'toronto-shared-bike-data-warehouse-data-bucket'
    RAW_URL = 'https://toronto-shared-bike-data-warehouse-data-bucket.s3.ca-central-1.amazonaws.com/raw/data.zip'
    S3_PREFIX  = "mv" 
    EXPORT_DIR = '/export'
  }

  stages {
    stage('Start PostgreSQL') {
      steps {
        dir(env.POSTGRES_DIR) { 
          sh '''
            docker compose down -v
            docker compose up -d --build
            sleep 30
            docker logs postgresql
          '''
          sh './build.sh' 
        }
      }
    }

    stage('Extract Data') {
      steps {
        sh '''
        docker exec -t postgresql bash /scripts/etl/extract.sh
        '''
      }
    }

    stage('Transform Data') {
      steps {
        sh '''
        docker exec -t postgresql bash /scripts/etl/transform.sh
        '''
      }
    }

    stage('Load Data') {
      steps {
        sh '''
        docker exec -t postgresql bash /scripts/etl/load.sh
        '''
      }
    }

    stage('Refresh MV') {
      steps {
        sh '''
        docker exec -t postgresql bash /scripts/mv/mv_refresh.sh
        '''
      }
    }

    stage('Export Data') {
      steps {
        sh '''
        docker exec -t postgresql bash /scripts/export/export.sh
        '''
      }
    }

    stage('Upload to S3') {
      steps {
        script{
          withAWS(credentials: 'toronto_shared_bike', region: 'ca-central-1') {
            s3Upload(
              bucket:"toronto-shared-bike-data-warehouse-data-bucket", 
              path:'test', 
              workingDir:'/export',
              includePathPattern:'**/*.csv',
            )
          }
        }
      }
    }
  }

  post {
    always {
      sh '''
      docker compose -f data-warehouse/postgresql/docker-compose.yaml down
      '''
    }
    
    failure {
      emailext (
        to: "tech.arguswatcher@gmail.com",
        subject: "FAILURE: ${env.JOB_NAME} - Build #${env.BUILD_NUMBER}",
        body: "The Jenkins pipeline '${env.JOB_NAME}' failed.\n" +
          "Build URL: ${env.BUILD_URL}",
      )
    }

    success {
      emailext (
        to: "tech.arguswatcher@gmail.com",
        subject: "SUCCESS: ${env.JOB_NAME} - Build #${env.BUILD_NUMBER}",
        body: "The Jenkins pipeline '${env.JOB_NAME}' completed successfully.\n" +
          "Build URL: ${env.BUILD_URL}",
      )
    }
  }
}
